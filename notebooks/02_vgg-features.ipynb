{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from helper.classification_tools import CustomLabelEncoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 10 filenames: ['Pa_286.bmp', 'RS_126.bmp', 'Sc_295.bmp', 'In_20.bmp', 'Cr_79.bmp', 'Cr_40.bmp', 'RS_214.bmp', 'In_180.bmp', 'Cr_274.bmp', 'RS_108.bmp']\n"
     ]
    }
   ],
   "source": [
    "img_root = Path('..','data','images_preprocessed','images_histeq_resize')  # directory where images are stored.\n",
    "assert img_root.is_dir() # make sure directory exists and is properly found\n",
    "files = sorted(img_root.glob(\"*.bmp\"))  # returns a list of all of the images in the directory, sorted by filename.\n",
    "\n",
    "## Shuffle the filenames so they appear randomly in the dataset. \n",
    "rs = np.random.RandomState(seed=749976)\n",
    "rs.shuffle(files)\n",
    "\n",
    "assert len(files) == 1800  # make sure all files are found.\n",
    "print('first 10 filenames: {}'.format([x.name for x in files[:10]]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the labels from filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 10 labels: ['Pa', 'RS', 'Sc', 'In', 'Cr', 'Cr', 'RS', 'In', 'Cr', 'RS']\n"
     ]
    }
   ],
   "source": [
    "def extract_labels(f): return [x.stem.split('_')[0] for x in f]\n",
    "labels = extract_labels(files)\n",
    "print('first 10 labels: {}'.format(labels[:10]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label encodings: {'Cr': 0, 'In': 1, 'Pa': 2, 'PS': 3, 'RS': 4, 'Sc': 5}\n",
      "first 10 integer labels: [2 4 5 1 0 0 4 1 0 4]\n",
      "first 10 string labels: ['Pa' 'RS' 'Sc' 'In' 'Cr' 'Cr' 'RS' 'In' 'Cr' 'RS']\n"
     ]
    }
   ],
   "source": [
    "le = CustomLabelEncoder()\n",
    "le.fit(labels, sorter=lambda x: x.upper())\n",
    "\n",
    "labels_int = le.transform(labels[:10])\n",
    "labels_str = le.inverse_transform(labels_int)\n",
    "\n",
    "\n",
    "with open(Path('..','models','label_encoder.pickle'), 'wb') as f:\n",
    "    pickle.dump(le, f)\n",
    "\n",
    "print('label encodings: {}'.format(le.mapper))\n",
    "print('first 10 integer labels: {}'.format(labels_int))\n",
    "print('first 10 string labels: {}'.format(labels_str))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(paths):\n",
    "    \"\"\"\n",
    "    Loads images in the correct format for use with the Keras VGG16 model\n",
    "    \n",
    "    Images are loaded as PIL image objects, converted to numpy array, and then formatted\n",
    "    with the appropriate VGG16.preprocess_input() function. Note that this only changes\n",
    "    how the images are represented, it does not change the actual visual properties of the\n",
    "    images like preprocessing did before.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    paths: list(Path)\n",
    "        list of Paths to each file where the image is stored. Note that the images should \n",
    "        have the same height, width in pixels so they can be stored in one array.\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    images: ndarray\n",
    "        n_images x r x c x 3 array of pixel values that is compatible with the Keras model.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    images = [image.load_img(file) for file in paths] # load images\n",
    "    # convert images to an array with shape consistent for the vgg16 input\n",
    "    images = np.asarray([image.img_to_array(img) for img in images]) \n",
    "    # normalizes the pixel values to match the imagenet format (and therefore the pre-trained weights)\n",
    "    images = preprocess_input(images) \n",
    "    \n",
    "    return images\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1800, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "images = load_images(files)\n",
    "assert len(images) == 1800\n",
    "print(images.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "vgg16_path = Path('..','models','VGG16.h5')\n",
    "if not vgg16_path.is_file():\n",
    "    vgg16 = keras.applications.VGG16(include_top=True,  # include fully connected layers\n",
    "                                     weights='imagenet') # use pre-trained model\n",
    "    vgg16.save(vgg16_path) # save model so we don't have to download it everytime\n",
    "    \n",
    "else:   \n",
    "    vgg16 = keras.models.load_model(vgg16_path) # use saved model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pre-trained model will run data through the entire network and return the output of the classification layer. \n",
    "\n",
    "Howevever, we only want the output of the intermediate layer so that we can use it as a feature descriptor. \n",
    "\n",
    "By default, we will use the fc1 (first fully-connected layer), but we will use other layers as well in the sensitivity analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_extractor(model=vgg16, layer='fc1'):\n",
    "    \"\"\"\n",
    "    returns a model that will extract the outputs of *layer* from *model*.\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    model: keras model\n",
    "        full model from which intermediate layer will be extracted\n",
    "    layer: string\n",
    "        name of layer from which to extract outputs\n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    new_model: keras model\n",
    "        feature extractor model which takes the same inputs as *model* and returns the outputs\n",
    "        of the intermediate layer specified by *layer* by calling new_model.predict(inputs)\n",
    "    \"\"\"\n",
    "    assert layer in [x.name for x in model.layers]  # make sure the layer exists\n",
    "\n",
    "    new_model = keras.Model(inputs = vgg16.input, outputs=[vgg16.get_layer(layer).output])\n",
    "    \n",
    "    return new_model\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FC1 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 156s 3s/step\n",
      "(1800, 4096)\n"
     ]
    }
   ],
   "source": [
    "fc1_extractor = layer_extractor()\n",
    "fc1 = fc1_extractor.predict(images, verbose=True)\n",
    "\n",
    "# save results\n",
    "results = {'filename' : files,\n",
    "           'features': fc1,\n",
    "          'labels': labels,\n",
    "           'layer_name': 'fc1'\n",
    "          }\n",
    "\n",
    "feature_dir = Path('..','data','features')\n",
    "os.makedirs(feature_dir, exist_ok=True)\n",
    "with open(feature_dir / 'VGG16_fc1_features_std.pickle', 'wb') as f:\n",
    "    pickle.dump(results, f)\n",
    "\n",
    "print(fc1.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features from other layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'block3_conv2' in [x.name for x in vgg16.layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting features: fc2\n",
      "57/57 [==============================] - 152s 3s/step\n",
      "extracting features: block5_pool\n",
      "57/57 [==============================] - 150s 3s/step\n",
      "extracting features: block5_conv3\n",
      "57/57 [==============================] - 150s 3s/step\n"
     ]
    }
   ],
   "source": [
    "for layer in ['fc2', 'block5_pool', 'block5_conv3']:\n",
    "    print(f'extracting features: {layer}')\n",
    "    extractor = layer_extractor(layer=layer)  # model to extract features for each layer\n",
    "    features = extractor.predict(images, verbose=True)  # features extracted by model\n",
    "    # save the results using the same format as before\n",
    "    results = {'filename': files,\n",
    "              'features': features,\n",
    "              'labels': labels,\n",
    "              'layer_name': layer}\n",
    "    with open(feature_dir / 'VGG16_{}_features.pickle'.format(layer), 'wb') as f:\n",
    "        pickle.dump(results, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FC1 features without histogram equalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 5 filenames and labels\n",
      "['Pa_291.bmp', 'Pa_116.bmp', 'Cr_136.bmp', 'Cr_232.bmp', 'Pa_188.bmp']\n",
      "['Pa', 'Pa', 'Cr', 'Cr', 'Pa']\n"
     ]
    }
   ],
   "source": [
    "img_root_nohisteq = Path('..','data','images_preprocessed','images_resize')\n",
    "assert img_root_nohisteq.is_dir()\n",
    "files_noh = sorted(img_root_nohisteq.glob('*'))\n",
    "rs = np.random.RandomState(seed=3626210179)\n",
    "rs.shuffle(files_noh)\n",
    "labels_noh = extract_labels(files_noh)\n",
    "assert len(files_noh) == 1800\n",
    "print('first 5 filenames and labels')\n",
    "print([x.name for x in files_noh[:5]])\n",
    "print(labels_noh[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 153s 3s/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "images_noh = load_images(files_noh)\n",
    "fc1_noh = fc1_extractor.predict(images_noh, verbose=True)\n",
    "\n",
    "results = {'filename': files_noh,\n",
    "          'features': fc1_noh,\n",
    "          'labels': labels_noh,\n",
    "          'layer_name': 'fc1 no_histeq'}\n",
    "with open(feature_dir / 'VGG16_fc1_features_NoHistEQ.pickle', 'wb') as f:\n",
    "    pickle.dump(results, f)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
